import torch, torch.nn as nn
import snntorch as snn
import snntorch.spikegen as spikegen
import matplotlib.pyplot as plt
import snntorch.spikeplot as splt
from IPython.display import HTML, display
import matplotlib
matplotlib.rcParams['animation.writer'] = 'pillow'

# Training Parameters
batch_size=128
data_path='/tmp/data/mnist'
num_classes = 10  # MNIST has 10 output classes

device = torch.device("cuda") if torch.cuda.is_available() else torch.device('mps') if torch.backends.mps.is_available() else torch.device("cpu")

# Testing and training data
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# Use MNIST instead of FashionMNIST, and remove extra normalization
transform = transforms.Compose([
    transforms.Resize((28, 28)),
    transforms.Grayscale(),
    transforms.ToTensor()
])

mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)
mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)

train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True)



## REQUIRED POPULATION CODING ##


def powerlaw_conv(data, alpha=1.5, min_val=1e-6):
    clipped_data = torch.clamp(data, min=min_val, max=1.0)
    uniform_random = torch.rand_like(clipped_data)
    
    if alpha != 1.0:
        powerlaw_samples = (1 - uniform_random) ** (-1/(alpha - 1))
    else:
        powerlaw_samples = -torch.log(uniform_random)
    
    # Rescale powerlaw_samples to [0, 1]
    powerlaw_samples = (powerlaw_samples - powerlaw_samples.min()) / (powerlaw_samples.max() - powerlaw_samples.min() + 1e-8)
    spike_probability = clipped_data * powerlaw_samples
    spike_probability = torch.clamp(spike_probability, 0, 1)
    spike_data = torch.bernoulli(spike_probability)
    
    return spike_data

def modified_rate_encoding(data, num_steps=10, method='powerlaw', **kwargs):
    """Drop-in replacement for snntorch.spikegen.rate() with power-law option.
    
    Args:
        data: Input tensor
        num_steps: Number of time steps
        method: 'poisson' (original) or 'powerlaw' (critical)
        **kwargs: Additional arguments for power-law generation
    
    Returns:
        Spike tensor with chosen statistics
    """
    # Repeat data across time dimension
    time_data = data.repeat(tuple([num_steps] + [1] * len(data.shape)))
    
    if method == 'poisson':
        # Original snnTorch behavior
        spike_data = torch.bernoulli(torch.clamp(time_data, 0, 1))
    elif method == 'powerlaw':
        # Your critical avalanche modification
        spike_data = powerlaw_conv(time_data, **kwargs)
    else:
        raise ValueError(f"Unknown method: {method}")
    return spike_data


## OPTIONAL ... RATE CODING ##



## MAIN IMPLEMENTATION ##

if __name__ == "__main__":
    # Example: MNIST pixel values
    # Use only a small batch for encoding
    # mnist_data = fmnist_train.data[:100].float() / 255.0  # Only 100 subsamples
    mnist_data = mnist_train.data[0].unsqueeze(0).float()  # shape: [1, 28, 28]
    
    # Extract a sample of digits (e.g., one of each class)
    sample_images = []
    sample_labels = []
    num_samples_per_class = 1

    for i in range(len(mnist_train)):
        img, label = mnist_train[i]
        if label not in sample_labels:
            sample_images.append(img)
            sample_labels.append(label)
            if len(sample_labels) == 10: # Got one of each class
                break
    
    # Original Poisson encoding
    poisson_spikes = modified_rate_encoding(mnist_data, num_steps=100, method='poisson')
    
    # Power-law encoding for critical avalanches  
    critical_spikes = modified_rate_encoding(mnist_data, num_steps=100, 
                                           method='powerlaw', alpha=1.5)
    

    print("Poisson spikes shape:", poisson_spikes.shape)
    print("Critical spikes shape:", critical_spikes.shape)

    # Print a small slice for inspection
    print("Poisson spikes (first 2 time steps, first sample):")
    print(poisson_spikes[:2, 0])

    print("Critical spikes (first 2 time steps, first sample):")
    print(critical_spikes[:2, 0])

    # Print summary statistics
    print("Poisson spikes - mean:", poisson_spikes.float().mean().item(), "sum:", poisson_spikes.sum().item())
    print("Critical spikes - mean:", critical_spikes.float().mean().item(), "sum:", critical_spikes.sum().item())

    # Use a single MNIST digit
    img, label = mnist_train[0]
    img = img.squeeze()  # shape: [28, 28]
    img_flat = img.view(-1)  # shape: [784]

    num_steps = 100
    poisson_spikes = modified_rate_encoding(img_flat.unsqueeze(0), num_steps=num_steps, method='poisson')
    critical_spikes = modified_rate_encoding(img_flat.unsqueeze(0), num_steps=num_steps, method='powerlaw', alpha=1.5)

    from matplotlib.animation import PillowWriter
    from IPython.display import Image

    # Poisson GIF and raster
    fig, ax = plt.subplots()
    anim = splt.animator(poisson_spikes[:, 0].view(num_steps, 28, 28), fig, ax)
    anim.save("poisson.gif", writer=PillowWriter(fps=10))
    display(Image(filename="poisson.gif"))
    plt.close(fig)

    fig, ax = plt.subplots()
    splt.raster(poisson_spikes[:, 0], ax, s=0.5)
    ax.set_title("Poisson Raster Plot")
    plt.show()

    # Critical GIF and raster
    fig, ax = plt.subplots()
    anim = splt.animator(critical_spikes[:, 0].view(num_steps, 28, 28), fig, ax)
    anim.save("critical.gif", writer=PillowWriter(fps=10))
    display(Image(filename="critical.gif"))
    plt.close(fig)

    fig, ax = plt.subplots()
    splt.raster(critical_spikes[:, 0], ax, s=0.5)
    ax.set_title("Critical Raster Plot")
    plt.show()
